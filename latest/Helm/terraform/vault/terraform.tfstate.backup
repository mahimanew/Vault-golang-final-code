{
  "version": 4,
  "terraform_version": "1.9.2",
  "serial": 14,
  "lineage": "7ba23aae-a442-ecdd-4289-b439b3f33007",
  "outputs": {},
  "resources": [
    {
      "mode": "data",
      "type": "aws_eks_cluster",
      "name": "cluster",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "access_config": [
              {
                "authentication_mode": "API_AND_CONFIG_MAP",
                "bootstrap_cluster_creator_admin_permissions": true
              }
            ],
            "arn": "arn:aws:eks:us-east-1:767397950016:cluster/cluster-dev",
            "certificate_authority": [
              {
                "data": "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJVkFlWmR6TkdnSXd3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRFeU1UY3dPVE0xTlRKYUZ3MHpOREV5TVRVd09UUXdOVEphTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUNZN1pBQXhXdm9naFIwV3Y4b1c3TGNUTjF6TGQrK2Ira1dGbUJBaWd4TUExTUpUYWF1QzF2Qk1BUzEKRWdIYUhveGdSaDRmQmV2N1k4QjhxcCtIMlUyWVhYUmZjSWNqcC8zVVh0dU1vdDZQM2xSakx5dFN1d2l1L0h6RgpvamV1ZWcrb0w0bFJmVUl0MVJ2emxERW5sak85RXFoQ3NXeUJRL1M2QmRzY3FURlhyNmRSNm95d3d1MGVJUEtYCi9jYzNMbkNqNUpIYWNicFJCcGRDVXp0MDFXWlhQdTc1RGwzSEFqUmlXL2grWXZyNlJlZi9JNzlBQ1MzWmcwTUgKV29yb0VJN1JvQ01NTkYwb1VZRzJPRVNHK0x2eENmR0tsNFJUWjg4Mi9EZ2lxQUFXc1Z3WTEzdE8xUkpaczRISgpTRFM3UzMzZzRxVm9Yc2xQSzRBeDRXY3FnS0dMQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJRZXdMQ0NBa0kzSjJhUDBCNXVnc2xTV2xlSE1qQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQmNhdTlzWFlCUwp6RTlYR25jUEFDVzJWUjM5a2JNZHYzR1NuZU96Y1dnUDIxMkZJa1JBWCtFL0hBNEZDamhQQ201S3dkTlc4TWFDCmhpVGRJRXR6clVCZHVkYzRJS0FGOFkvdlBSak9oY2R2enFMNVNGNlB6OWtaVVBrZ0lrNHJQS20zVkFOc0JwRTcKS25HK1R3a29JM1VpT0Y4a1VqNlNISUgrNStFangzOEt1UzhVaE1IRjd6Rjc2bXRFOWllQkN4TUNZRjkwVlZxYQppR1ZpbXU0Z2VxdVVlK3EwdS9GYm8ySzlBS1BNaUdRQ2RqWHBNZGptTTArb2R2QUxVc2J5NGtoWVMrcTVGTnd1CjNKMy9XUW9lSGFEcEM5ZlNrMmtXNkEzaTZ4ekpZSjdGQzlFeFpwY1JYVUtjU2dzc0tvdEs3YU9tQVo2Q1l2V1gKY1FWQmdxMlUzUUROCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K"
              }
            ],
            "cluster_id": null,
            "compute_config": [],
            "created_at": "2024-12-17T09:36:10Z",
            "enabled_cluster_log_types": [],
            "endpoint": "https://48F1125BCC8DD3418816A72EE059E51F.gr7.us-east-1.eks.amazonaws.com",
            "id": "cluster-dev",
            "identity": [
              {
                "oidc": [
                  {
                    "issuer": "https://oidc.eks.us-east-1.amazonaws.com/id/48F1125BCC8DD3418816A72EE059E51F"
                  }
                ]
              }
            ],
            "kubernetes_network_config": [
              {
                "elastic_load_balancing": [
                  {
                    "enabled": false
                  }
                ],
                "ip_family": "ipv4",
                "service_ipv4_cidr": "10.100.0.0/16",
                "service_ipv6_cidr": ""
              }
            ],
            "name": "cluster-dev",
            "outpost_config": [],
            "platform_version": "eks.23",
            "remote_network_config": [],
            "role_arn": "arn:aws:iam::767397950016:role/eksctl-cluster-dev-cluster-ServiceRole-Wa1VhVgUGzdi",
            "status": "ACTIVE",
            "storage_config": [],
            "tags": {
              "Name": "eksctl-cluster-dev-cluster/ControlPlane",
              "alpha.eksctl.io/cluster-name": "cluster-dev",
              "alpha.eksctl.io/cluster-oidc-enabled": "false",
              "alpha.eksctl.io/eksctl-version": "0.194.0",
              "eksctl.cluster.k8s.io/v1alpha1/cluster-name": "cluster-dev"
            },
            "upgrade_policy": [
              {
                "support_type": "EXTENDED"
              }
            ],
            "version": "1.30",
            "vpc_config": [
              {
                "cluster_security_group_id": "sg-0330f0358340fdc40",
                "endpoint_private_access": false,
                "endpoint_public_access": true,
                "public_access_cidrs": [
                  "0.0.0.0/0"
                ],
                "security_group_ids": [
                  "sg-08c11b725c4ee281f"
                ],
                "subnet_ids": [
                  "subnet-0263fc1b38b8bed6b",
                  "subnet-077f3f4bb536bcfc6",
                  "subnet-08d97ae98b48b148b",
                  "subnet-0b951b1402366329e"
                ],
                "vpc_id": "vpc-04ffe65ba66d3a231"
              }
            ],
            "zonal_shift_config": []
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "aws_eks_cluster_auth",
      "name": "cluster",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "cluster-dev",
            "name": "cluster-dev",
            "token": "k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBM0ZMRDNPSkFNVFdDSjdYQiUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMThUMDgzOTQ4WiZYLUFtei1FeHBpcmVzPTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JTNCeC1rOHMtYXdzLWlkJlgtQW16LVNpZ25hdHVyZT05MzkxNjY1ODIzZGYyYjVjNjVjMjQ3NzY5NjZlOTY4YTg5OTk2ZTUyYTJiNjI4ZjI4OWNmYmJlZTE2MDM0ZmRi"
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "token"
              }
            ]
          ]
        }
      ]
    },
    {
      "mode": "data",
      "type": "kubernetes_secret",
      "name": "sa_token",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "ca.crt": "-----BEGIN CERTIFICATE-----\nMIIDBTCCAe2gAwIBAgIIVAeZdzNGgIwwDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yNDEyMTcwOTM1NTJaFw0zNDEyMTUwOTQwNTJaMBUx\nEzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQCY7ZAAxWvoghR0Wv8oW7LcTN1zLd++b+kWFmBAigxMA1MJTaauC1vBMAS1\nEgHaHoxgRh4fBev7Y8B8qp+H2U2YXXRfcIcjp/3UXtuMot6P3lRjLytSuwiu/HzF\nojeueg+oL4lRfUIt1RvzlDEnljO9EqhCsWyBQ/S6BdscqTFXr6dR6oywwu0eIPKX\n/cc3LnCj5JHacbpRBpdCUzt01WZXPu75Dl3HAjRiW/h+Yvr6Ref/I79ACS3Zg0MH\nWoroEI7RoCMMNF0oUYG2OESG+LvxCfGKl4RTZ882/DgiqAAWsVwY13tO1RJZs4HJ\nSDS7S33g4qVoXslPK4Ax4WcqgKGLAgMBAAGjWTBXMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQewLCCAkI3J2aP0B5ugslSWleHMjAV\nBgNVHREEDjAMggprdWJlcm5ldGVzMA0GCSqGSIb3DQEBCwUAA4IBAQBcau9sXYBS\nzE9XGncPACW2VR39kbMdv3GSneOzcWgP212FIkRAX+E/HA4FCjhPCm5KwdNW8MaC\nhiTdIEtzrUBdudc4IKAF8Y/vPRjOhcdvzqL5SF6Pz9kZUPkgIk4rPKm3VANsBpE7\nKnG+TwkoI3UiOF8kUj6SHIH+5+Ejx38KuS8UhMHF7zF76mtE9ieBCxMCYF90VVqa\niGVimu4gequUe+q0u/Fbo2K9AKPMiGQCdjXpMdjmM0+odvALUsby4khYS+q5FNwu\n3J3/WQoeHaDpC9fSk2kW6A3i6xzJYJ7FC9ExZpcRXUKcSgssKotK7aOmAZ6CYvWX\ncQVBgq2U3QDN\n-----END CERTIFICATE-----\n",
              "namespace": "vault",
              "token": "eyJhbGciOiJSUzI1NiIsImtpZCI6InlYb1QxbmhZS2pnYTdOR3dxenBKMU8wRWJlMmhvRUVmYXpWZWxQbEJnbVEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJ2YXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ2YXVsdC1zYS10b2tlbiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJ2YXVsdC1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBmNjllYzgzLTljODYtNDRhYy1iYzBkLWNiNDhiN2FmNTEyMiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDp2YXVsdDp2YXVsdC1zYSJ9.ebaAYjDMz7lWq_LI1B6yzx8hA-1ac8gRDkSwfmKjschfiQsW72fyDD6wBVPDSWJrHx0H85ethOTZwVfj86Rwh2rPy5ZlCMtw-ezGwuHW5KJ9Tu7TE3lU9ZESsWWhVko-jDPMNHMBuaUxe3jfOL9TsrlY_PBES_lXuF0Ds_WeAW_MK3Md0Lw3MWTBWIPY1i7e97C3nC_7cxHfItJlyuNcLIAXDpIjb3eaAJAJig5PURJwP7d5w-J6JtpaG8SFbnACzsz-VSeZ5Hxn2IfdacHIPExIVST_RQTVA3o3KYOPORJmR7XeLgD9uhQGZABabTSi2acAzV-IEIRcloy3RltHFA"
            },
            "id": "vault/vault-sa-token",
            "immutable": false,
            "metadata": [
              {
                "annotations": {
                  "kubernetes.io/service-account.name": "vault-sa",
                  "kubernetes.io/service-account.uid": "0f69ec83-9c86-44ac-bc0d-cb48b7af5122",
                  "meta.helm.sh/release-name": "vault",
                  "meta.helm.sh/release-namespace": "vault"
                },
                "generate_name": "",
                "generation": 0,
                "labels": {
                  "app.kubernetes.io/instance": "vault",
                  "app.kubernetes.io/managed-by": "Helm",
                  "app.kubernetes.io/name": "vault",
                  "helm.sh/chart": "vault-0.29.1"
                },
                "name": "vault-sa-token",
                "namespace": "vault",
                "resource_version": "229618",
                "uid": "694b1eec-ea84-4b11-b4af-a7485af6b01e"
              }
            ],
            "type": "kubernetes.io/service-account-token"
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "binary_data"
              }
            ],
            [
              {
                "type": "get_attr",
                "value": "data"
              }
            ]
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "vault",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "vault",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "vault",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.18.1",
                "chart": "vault",
                "first_deployed": 1734510972,
                "last_deployed": 1734510972,
                "name": "vault",
                "namespace": "vault",
                "notes": "\nThank you for installing HashiCorp Vault!\n\nNow that you have deployed Vault, you should look over the docs on using\nVault with Kubernetes available here:\n\nhttps://developer.hashicorp.com/vault/docs\n\n\nYour release is named vault. To learn more about the release, try:\n\n  $ helm status vault\n  $ helm get manifest vault\n\n",
                "revision": 1,
                "values": "{\"csi\":{\"agent\":{\"enabled\":true,\"extraArgs\":[],\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"hashicorp/vault\",\"tag\":\"1.18.1\"},\"logFormat\":\"standard\",\"logLevel\":\"info\",\"resources\":{}},\"daemonSet\":{\"annotations\":{},\"extraLabels\":{},\"kubeletRootDir\":\"/var/lib/kubelet\",\"providersDir\":\"/etc/kubernetes/secrets-store-csi-providers\",\"securityContext\":{\"container\":{},\"pod\":{}},\"updateStrategy\":{\"maxUnavailable\":\"\",\"type\":\"RollingUpdate\"}},\"debug\":false,\"enabled\":false,\"extraArgs\":[],\"hmacSecretName\":\"\",\"hostNetwork\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"hashicorp/vault-csi-provider\",\"tag\":\"1.5.0\"},\"livenessProbe\":{\"failureThreshold\":2,\"initialDelaySeconds\":5,\"periodSeconds\":5,\"successThreshold\":1,\"timeoutSeconds\":3},\"logLevel\":\"info\",\"pod\":{\"affinity\":{},\"annotations\":{},\"extraLabels\":{},\"nodeSelector\":{},\"tolerations\":[]},\"priorityClassName\":\"\",\"readinessProbe\":{\"failureThreshold\":2,\"initialDelaySeconds\":5,\"periodSeconds\":5,\"successThreshold\":1,\"timeoutSeconds\":3},\"resources\":{},\"serviceAccount\":{\"annotations\":{},\"extraLabels\":{}},\"volumeMounts\":null,\"volumes\":null},\"global\":{\"enabled\":true,\"externalVaultAddr\":\"https://34.203.226.62:8202/\",\"imagePullSecrets\":[],\"namespace\":\"vault\",\"openshift\":false,\"psp\":{\"annotations\":\"seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default,runtime/default\\napparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default\\nseccomp.security.alpha.kubernetes.io/defaultProfileName:  runtime/default\\napparmor.security.beta.kubernetes.io/defaultProfileName:  runtime/default\\n\",\"enable\":false},\"serverTelemetry\":{\"prometheusOperator\":false},\"tlsDisable\":true},\"injector\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          app.kubernetes.io/name: {{ template \\\"vault.name\\\" . }}-agent-injector\\n          app.kubernetes.io/instance: \\\"{{ .Release.Name }}\\\"\\n          component: webhook\\n      topologyKey: kubernetes.io/hostname\\n\",\"agentDefaults\":{\"cpuLimit\":\"500m\",\"cpuRequest\":\"250m\",\"memLimit\":\"128Mi\",\"memRequest\":\"64Mi\",\"template\":\"map\",\"templateConfig\":{\"exitOnRetryFailure\":true,\"staticSecretRenderInterval\":\"\"}},\"agentImage\":{\"repository\":\"hashicorp/vault\",\"tag\":\"1.18.1\"},\"annotations\":{},\"authPath\":\"auth/kubernetes\",\"certs\":{\"caBundle\":\"\",\"certName\":\"tls.crt\",\"keyName\":\"tls.key\",\"secretName\":null},\"enabled\":\"true\",\"externalVaultAddr\":\"\",\"extraEnvironmentVars\":{},\"extraLabels\":{},\"failurePolicy\":\"Ignore\",\"hostNetwork\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"hashicorp/vault-k8s\",\"tag\":\"1.5.0\"},\"leaderElector\":{\"enabled\":true},\"livenessProbe\":{\"failureThreshold\":2,\"initialDelaySeconds\":5,\"periodSeconds\":2,\"successThreshold\":1,\"timeoutSeconds\":5},\"logFormat\":\"standard\",\"logLevel\":\"info\",\"metrics\":{\"enabled\":false},\"namespaceSelector\":{},\"nodeSelector\":{},\"objectSelector\":{},\"podDisruptionBudget\":{},\"port\":8080,\"priorityClassName\":\"\",\"readinessProbe\":{\"failureThreshold\":2,\"initialDelaySeconds\":5,\"periodSeconds\":2,\"successThreshold\":1,\"timeoutSeconds\":5},\"replicas\":1,\"resources\":{},\"revokeOnShutdown\":false,\"securityContext\":{\"container\":{},\"pod\":{}},\"service\":{\"annotations\":{}},\"serviceAccount\":{\"annotations\":{}},\"startupProbe\":{\"failureThreshold\":12,\"initialDelaySeconds\":5,\"periodSeconds\":5,\"successThreshold\":1,\"timeoutSeconds\":5},\"strategy\":{},\"tolerations\":[],\"topologySpreadConstraints\":[],\"webhook\":{\"annotations\":{},\"failurePolicy\":\"Ignore\",\"matchPolicy\":\"Exact\",\"namespaceSelector\":{},\"objectSelector\":\"matchExpressions:\\n- key: app.kubernetes.io/name\\n  operator: NotIn\\n  values:\\n  - {{ template \\\"vault.name\\\" . }}-agent-injector\\n\",\"timeoutSeconds\":30},\"webhookAnnotations\":{}},\"server\":{\"affinity\":\"podAntiAffinity:\\n  requiredDuringSchedulingIgnoredDuringExecution:\\n    - labelSelector:\\n        matchLabels:\\n          app.kubernetes.io/name: {{ template \\\"vault.name\\\" . }}\\n          app.kubernetes.io/instance: \\\"{{ .Release.Name }}\\\"\\n          component: server\\n      topologyKey: kubernetes.io/hostname\\n\",\"annotations\":{},\"auditStorage\":{\"accessMode\":\"ReadWriteOnce\",\"annotations\":{},\"enabled\":false,\"labels\":{},\"mountPath\":\"/vault/audit\",\"size\":\"10Gi\",\"storageClass\":null},\"authDelegator\":{\"enabled\":true},\"dataStorage\":{\"accessMode\":\"ReadWriteOnce\",\"annotations\":{},\"enabled\":true,\"labels\":{},\"mountPath\":\"/vault/data\",\"size\":\"10Gi\",\"storageClass\":null},\"dev\":{\"devRootToken\":\"root\",\"enabled\":false},\"enabled\":\"-\",\"enterpriseLicense\":{\"secretKey\":\"license\",\"secretName\":\"\"},\"extraArgs\":\"\",\"extraContainers\":null,\"extraEnvironmentVars\":{},\"extraInitContainers\":null,\"extraLabels\":{},\"extraPorts\":null,\"extraSecretEnvironmentVars\":[],\"extraVolumes\":[],\"ha\":{\"apiAddr\":null,\"clusterAddr\":null,\"config\":\"ui = true\\n\\nlistener \\\"tcp\\\" {\\n  tls_disable = 1\\n  address = \\\"[::]:8200\\\"\\n  cluster_address = \\\"[::]:8201\\\"\\n}\\nstorage \\\"consul\\\" {\\n  path = \\\"vault\\\"\\n  address = \\\"HOST_IP:8500\\\"\\n}\\n\\nservice_registration \\\"kubernetes\\\" {}\\n\\n# Example configuration for using auto-unseal, using Google Cloud KMS. The\\n# GKMS keys must already exist, and the cluster must have a service account\\n# that is authorized to access GCP KMS.\\n#seal \\\"gcpckms\\\" {\\n#   project     = \\\"vault-helm-dev-246514\\\"\\n#   region      = \\\"global\\\"\\n#   key_ring    = \\\"vault-helm-unseal-kr\\\"\\n#   crypto_key  = \\\"vault-helm-unseal-key\\\"\\n#}\\n\\n# Example configuration for enabling Prometheus metrics.\\n# If you are using Prometheus Operator you can enable a ServiceMonitor resource below.\\n# You may wish to enable unauthenticated metrics in the listener block above.\\n#telemetry {\\n#  prometheus_retention_time = \\\"30s\\\"\\n#  disable_hostname = true\\n#}\\n\",\"disruptionBudget\":{\"enabled\":true,\"maxUnavailable\":null},\"enabled\":false,\"raft\":{\"config\":\"ui = true\\n\\nlistener \\\"tcp\\\" {\\n  tls_disable = 1\\n  address = \\\"[::]:8200\\\"\\n  cluster_address = \\\"[::]:8201\\\"\\n  # Enable unauthenticated metrics access (necessary for Prometheus Operator)\\n  #telemetry {\\n  #  unauthenticated_metrics_access = \\\"true\\\"\\n  #}\\n}\\n\\nstorage \\\"raft\\\" {\\n  path = \\\"/vault/data\\\"\\n}\\n\\nservice_registration \\\"kubernetes\\\" {}\\n\",\"enabled\":false,\"setNodeId\":false},\"replicas\":3},\"hostAliases\":[],\"hostNetwork\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"repository\":\"hashicorp/vault\",\"tag\":\"1.18.1\"},\"includeConfigAnnotation\":false,\"ingress\":{\"activeService\":true,\"annotations\":{},\"enabled\":false,\"extraPaths\":[],\"hosts\":[{\"host\":\"chart-example.local\",\"paths\":[]}],\"ingressClassName\":\"\",\"labels\":{},\"pathType\":\"Prefix\",\"tls\":[]},\"livenessProbe\":{\"enabled\":false,\"execCommand\":[],\"failureThreshold\":2,\"initialDelaySeconds\":60,\"path\":\"/v1/sys/health?standbyok=true\",\"periodSeconds\":5,\"port\":8200,\"successThreshold\":1,\"timeoutSeconds\":3},\"logFormat\":\"\",\"logLevel\":\"\",\"networkPolicy\":{\"egress\":[],\"enabled\":false,\"ingress\":[{\"from\":[{\"namespaceSelector\":{}}],\"ports\":[{\"port\":8200,\"protocol\":\"TCP\"},{\"port\":8201,\"protocol\":\"TCP\"}]}]},\"nodeSelector\":{},\"persistentVolumeClaimRetentionPolicy\":{},\"postStart\":[],\"preStopSleepSeconds\":5,\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":2,\"initialDelaySeconds\":5,\"periodSeconds\":5,\"port\":8200,\"successThreshold\":1,\"timeoutSeconds\":3},\"resources\":{},\"route\":{\"activeService\":true,\"annotations\":{},\"enabled\":false,\"host\":\"chart-example.local\",\"labels\":{},\"tls\":{\"termination\":\"passthrough\"}},\"service\":{\"active\":{\"annotations\":{},\"enabled\":true},\"annotations\":{},\"enabled\":true,\"externalTrafficPolicy\":\"Cluster\",\"instanceSelector\":{\"enabled\":true},\"ipFamilies\":[],\"ipFamilyPolicy\":\"\",\"port\":8200,\"publishNotReadyAddresses\":true,\"standby\":{\"annotations\":{},\"enabled\":true},\"targetPort\":8200},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"createSecret\":true,\"extraLabels\":{},\"name\":\"vault-sa\",\"serviceDiscovery\":{\"enabled\":true}},\"shareProcessNamespace\":false,\"standalone\":{\"config\":\"ui = true\\n\\nlistener \\\"tcp\\\" {\\n  tls_disable = 1\\n  address = \\\"[::]:8200\\\"\\n  cluster_address = \\\"[::]:8201\\\"\\n  # Enable unauthenticated metrics access (necessary for Prometheus Operator)\\n  #telemetry {\\n  #  unauthenticated_metrics_access = \\\"true\\\"\\n  #}\\n}\\nstorage \\\"file\\\" {\\n  path = \\\"/vault/data\\\"\\n}\\n\\n# Example configuration for using auto-unseal, using Google Cloud KMS. The\\n# GKMS keys must already exist, and the cluster must have a service account\\n# that is authorized to access GCP KMS.\\n#seal \\\"gcpckms\\\" {\\n#   project     = \\\"vault-helm-dev\\\"\\n#   region      = \\\"global\\\"\\n#   key_ring    = \\\"vault-helm-unseal-kr\\\"\\n#   crypto_key  = \\\"vault-helm-unseal-key\\\"\\n#}\\n\\n# Example configuration for enabling Prometheus metrics in your config.\\n#telemetry {\\n#  prometheus_retention_time = \\\"30s\\\"\\n#  disable_hostname = true\\n#}\",\"enabled\":\"-\"},\"statefulSet\":{\"annotations\":{},\"securityContext\":{\"container\":{},\"pod\":{}}},\"terminationGracePeriodSeconds\":10,\"tolerations\":[],\"topologySpreadConstraints\":[],\"updateStrategyType\":\"OnDelete\",\"volumeMounts\":null,\"volumes\":null},\"serverTelemetry\":{\"prometheusRules\":{\"enabled\":false,\"rules\":[],\"selectors\":{}},\"serviceMonitor\":{\"authorization\":{},\"enabled\":false,\"interval\":\"30s\",\"scrapeTimeout\":\"10s\",\"selectors\":{},\"tlsConfig\":{}}},\"ui\":{\"activeVaultPodOnly\":false,\"annotations\":{},\"enabled\":false,\"externalPort\":8200,\"externalTrafficPolicy\":\"Cluster\",\"publishNotReadyAddresses\":true,\"serviceIPFamilies\":[],\"serviceIPFamilyPolicy\":\"\",\"serviceNodePort\":null,\"serviceType\":\"ClusterIP\",\"targetPort\":8200}}",
                "version": "0.29.1"
              }
            ],
            "name": "vault",
            "namespace": "vault",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://helm.releases.hashicorp.com",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "upgrade_install": null,
            "values": [
              "# Copyright (c) HashiCorp, Inc.\r\n# SPDX-License-Identifier: MPL-2.0\r\n\r\n# Available parameters and their default values for the Vault chart.\r\n\r\nglobal:\r\n  # enabled is the master enabled switch. Setting this to true or false\r\n  # will enable or disable all the components within this chart by default.\r\n  enabled: true\r\n\r\n  # The namespace to deploy to. Defaults to the `helm` installation namespace.\r\n  namespace: \"vault\"\r\n\r\n  # Image pull secret to use for registry authentication.\r\n  # Alternatively, the value may be specified as an array of strings.\r\n  imagePullSecrets: []\r\n  # imagePullSecrets:\r\n  #   - name: image-pull-secret\r\n\r\n  # TLS for end-to-end encrypted transport\r\n  tlsDisable: true\r\n\r\n  # External vault server address for the injector and CSI provider to use.\r\n  # Setting this will disable deployment of a vault server.\r\n  externalVaultAddr: \"https://34.203.226.62:8202/\"\r\n\r\n  # If deploying to OpenShift\r\n  openshift: false\r\n\r\n  # Create PodSecurityPolicy for pods\r\n  psp:\r\n    enable: false\r\n    # Annotation for PodSecurityPolicy.\r\n    # This is a multi-line templated string map, and can also be set as YAML.\r\n    annotations: |\r\n      seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default,runtime/default\r\n      apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default\r\n      seccomp.security.alpha.kubernetes.io/defaultProfileName:  runtime/default\r\n      apparmor.security.beta.kubernetes.io/defaultProfileName:  runtime/default\r\n\r\n  serverTelemetry:\r\n    # Enable integration with the Prometheus Operator\r\n    # See the top level serverTelemetry section below before enabling this feature.\r\n    prometheusOperator: false\r\n\r\ninjector:\r\n  # True if you want to enable vault agent injection.\r\n  # @default: global.enabled\r\n  enabled: \"true\"\r\n\r\n  replicas: 1\r\n\r\n  # Configures the port the injector should listen on\r\n  port: 8080\r\n\r\n  # If multiple replicas are specified, by default a leader will be determined\r\n  # so that only one injector attempts to create TLS certificates.\r\n  leaderElector:\r\n    enabled: true\r\n\r\n  # If true, will enable a node exporter metrics endpoint at /metrics.\r\n  metrics:\r\n    enabled: false\r\n\r\n  # Deprecated: Please use global.externalVaultAddr instead.\r\n  externalVaultAddr: \"\"\r\n\r\n  # image sets the repo and tag of the vault-k8s image to use for the injector.\r\n  image:\r\n    repository: \"hashicorp/vault-k8s\"\r\n    tag: \"1.5.0\"\r\n    pullPolicy: IfNotPresent\r\n\r\n  # agentImage sets the repo and tag of the Vault image to use for the Vault Agent\r\n  # containers.  This should be set to the official Vault image.  Vault 1.3.1+ is\r\n  # required.\r\n  agentImage:\r\n    repository: \"hashicorp/vault\"\r\n    tag: \"1.18.1\"\r\n\r\n  # The default values for the injected Vault Agent containers.\r\n  agentDefaults:\r\n    # For more information on configuring resources, see the K8s documentation:\r\n    # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\r\n    cpuLimit: \"500m\"\r\n    cpuRequest: \"250m\"\r\n    memLimit: \"128Mi\"\r\n    memRequest: \"64Mi\"\r\n    # ephemeralLimit: \"128Mi\"\r\n    # ephemeralRequest: \"64Mi\"\r\n\r\n    # Default template type for secrets when no custom template is specified.\r\n    # Possible values include: \"json\" and \"map\".\r\n    template: \"map\"\r\n\r\n    # Default values within Agent's template_config stanza.\r\n    templateConfig:\r\n      exitOnRetryFailure: true\r\n      staticSecretRenderInterval: \"\"\r\n\r\n  # Used to define custom livenessProbe settings\r\n  livenessProbe:\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 2\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 5\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 2\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 5\r\n  # Used to define custom readinessProbe settings\r\n  readinessProbe:\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 2\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 5\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 2\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 5\r\n  # Used to define custom startupProbe settings\r\n  startupProbe:\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 12\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 5\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 5\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 5\r\n\r\n  # Mount Path of the Vault Kubernetes Auth Method.\r\n  authPath: \"auth/kubernetes\"\r\n\r\n  # Configures the log verbosity of the injector.\r\n  # Supported log levels include: trace, debug, info, warn, error\r\n  logLevel: \"info\"\r\n\r\n  # Configures the log format of the injector. Supported log formats: \"standard\", \"json\".\r\n  logFormat: \"standard\"\r\n\r\n  # Configures all Vault Agent sidecars to revoke their token when shutting down\r\n  revokeOnShutdown: false\r\n\r\n  webhook:\r\n    # Configures failurePolicy of the webhook. The \"unspecified\" default behaviour depends on the\r\n    # API Version of the WebHook.\r\n    # To block pod creation while the webhook is unavailable, set the policy to `Fail` below.\r\n    # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#failure-policy\r\n    #\r\n    failurePolicy: Ignore\r\n\r\n    # matchPolicy specifies the approach to accepting changes based on the rules of\r\n    # the MutatingWebhookConfiguration.\r\n    # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-matchpolicy\r\n    # for more details.\r\n    #\r\n    matchPolicy: Exact\r\n\r\n    # timeoutSeconds is the amount of seconds before the webhook request will be ignored\r\n    # or fails.\r\n    # If it is ignored or fails depends on the failurePolicy\r\n    # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#timeouts\r\n    # for more details.\r\n    #\r\n    timeoutSeconds: 30\r\n\r\n    # namespaceSelector is the selector for restricting the webhook to only\r\n    # specific namespaces.\r\n    # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-namespaceselector\r\n    # for more details.\r\n    # Example:\r\n    # namespaceSelector:\r\n    #    matchLabels:\r\n    #      sidecar-injector: enabled\r\n    namespaceSelector: {}\r\n\r\n    # objectSelector is the selector for restricting the webhook to only\r\n    # specific labels.\r\n    # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-objectselector\r\n    # for more details.\r\n    # Example:\r\n    # objectSelector:\r\n    #    matchLabels:\r\n    #      vault-sidecar-injector: enabled\r\n    objectSelector: |\r\n      matchExpressions:\r\n      - key: app.kubernetes.io/name\r\n        operator: NotIn\r\n        values:\r\n        - {{ template \"vault.name\" . }}-agent-injector\r\n\r\n    # Extra annotations to attach to the webhook\r\n    annotations: {}\r\n\r\n  # Deprecated: please use 'webhook.failurePolicy' instead\r\n  # Configures failurePolicy of the webhook. The \"unspecified\" default behaviour depends on the\r\n  # API Version of the WebHook.\r\n  # To block pod creation while webhook is unavailable, set the policy to `Fail` below.\r\n  # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#failure-policy\r\n  #\r\n  failurePolicy: Ignore\r\n\r\n  # Deprecated: please use 'webhook.namespaceSelector' instead\r\n  # namespaceSelector is the selector for restricting the webhook to only\r\n  # specific namespaces.\r\n  # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-namespaceselector\r\n  # for more details.\r\n  # Example:\r\n  # namespaceSelector:\r\n  #    matchLabels:\r\n  #      sidecar-injector: enabled\r\n  namespaceSelector: {}\r\n\r\n  # Deprecated: please use 'webhook.objectSelector' instead\r\n  # objectSelector is the selector for restricting the webhook to only\r\n  # specific labels.\r\n  # See https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-objectselector\r\n  # for more details.\r\n  # Example:\r\n  # objectSelector:\r\n  #    matchLabels:\r\n  #      vault-sidecar-injector: enabled\r\n  objectSelector: {}\r\n\r\n  # Deprecated: please use 'webhook.annotations' instead\r\n  # Extra annotations to attach to the webhook\r\n  webhookAnnotations: {}\r\n\r\n  certs:\r\n    # secretName is the name of the secret that has the TLS certificate and\r\n    # private key to serve the injector webhook. If this is null, then the\r\n    # injector will default to its automatic management mode that will assign\r\n    # a service account to the injector to generate its own certificates.\r\n    secretName: null\r\n\r\n    # caBundle is a base64-encoded PEM-encoded certificate bundle for the CA\r\n    # that signed the TLS certificate that the webhook serves. This must be set\r\n    # if secretName is non-null unless an external service like cert-manager is\r\n    # keeping the caBundle updated.\r\n    caBundle: \"\"\r\n\r\n    # certName and keyName are the names of the files within the secret for\r\n    # the TLS cert and private key, respectively. These have reasonable\r\n    # defaults but can be customized if necessary.\r\n    certName: tls.crt\r\n    keyName: tls.key\r\n\r\n  # Security context for the pod template and the injector container\r\n  # The default pod securityContext is:\r\n  #   runAsNonRoot: true\r\n  #   runAsGroup: {{ .Values.injector.gid | default 1000 }}\r\n  #   runAsUser: {{ .Values.injector.uid | default 100 }}\r\n  #   fsGroup: {{ .Values.injector.gid | default 1000 }}\r\n  # and for container is\r\n  #    allowPrivilegeEscalation: false\r\n  #    capabilities:\r\n  #      drop:\r\n  #        - ALL\r\n  securityContext:\r\n    pod: {}\r\n    container: {}\r\n\r\n  resources: {}\r\n  # resources:\r\n  #   requests:\r\n  #     memory: 256Mi\r\n  #     cpu: 250m\r\n  #   limits:\r\n  #     memory: 256Mi\r\n  #     cpu: 250m\r\n\r\n  # extraEnvironmentVars is a list of extra environment variables to set in the\r\n  # injector deployment.\r\n  extraEnvironmentVars:\r\n    {}\r\n    # KUBERNETES_SERVICE_HOST: kubernetes.default.svc\r\n\r\n  # Affinity Settings for injector pods\r\n  # This can either be a multi-line string or YAML matching the PodSpec's affinity field.\r\n  # Commenting out or setting as empty the affinity variable, will allow\r\n  # deployment of multiple replicas to single node services such as Minikube.\r\n  affinity: |\r\n    podAntiAffinity:\r\n      requiredDuringSchedulingIgnoredDuringExecution:\r\n        - labelSelector:\r\n            matchLabels:\r\n              app.kubernetes.io/name: {{ template \"vault.name\" . }}-agent-injector\r\n              app.kubernetes.io/instance: \"{{ .Release.Name }}\"\r\n              component: webhook\r\n          topologyKey: kubernetes.io/hostname\r\n\r\n  # Topology settings for injector pods\r\n  # ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\r\n  # This should be either a multi-line string or YAML matching the topologySpreadConstraints array\r\n  # in a PodSpec.\r\n  topologySpreadConstraints: []\r\n\r\n  # Toleration Settings for injector pods\r\n  # This should be either a multi-line string or YAML matching the Toleration array\r\n  # in a PodSpec.\r\n  tolerations: []\r\n\r\n  # nodeSelector labels for server pod assignment, formatted as a multi-line string or YAML map.\r\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\r\n  # Example:\r\n  # nodeSelector:\r\n  #   beta.kubernetes.io/arch: amd64\r\n  nodeSelector: {}\r\n\r\n  # Priority class for injector pods\r\n  priorityClassName: \"\"\r\n\r\n  # Extra annotations to attach to the injector pods\r\n  # This can either be YAML or a YAML-formatted multi-line templated string map\r\n  # of the annotations to apply to the injector pods\r\n  annotations: {}\r\n\r\n  # Extra labels to attach to the agent-injector\r\n  # This should be a YAML map of the labels to apply to the injector\r\n  extraLabels: {}\r\n\r\n  # Should the injector pods run on the host network (useful when using\r\n  # an alternate CNI in EKS)\r\n  hostNetwork: false\r\n\r\n  # Injector service specific config\r\n  service:\r\n    # Extra annotations to attach to the injector service\r\n    annotations: {}\r\n\r\n  # Injector serviceAccount specific config\r\n  serviceAccount:\r\n    # Extra annotations to attach to the injector serviceAccount\r\n    annotations: {}\r\n\r\n  # A disruption budget limits the number of pods of a replicated application\r\n  # that are down simultaneously from voluntary disruptions\r\n  podDisruptionBudget: {}\r\n  # podDisruptionBudget:\r\n  #   maxUnavailable: 1\r\n\r\n  # strategy for updating the deployment. This can be a multi-line string or a\r\n  # YAML map.\r\n  strategy: {}\r\n  # strategy: |\r\n  #   rollingUpdate:\r\n  #     maxSurge: 25%\r\n  #     maxUnavailable: 25%\r\n  #   type: RollingUpdate\r\n\r\nserver:\r\n  # If true, or \"-\" with global.enabled true, Vault server will be installed.\r\n  # See vault.mode in _helpers.tpl for implementation details.\r\n  enabled: \"-\"\r\n\r\n  # [Enterprise Only] This value refers to a Kubernetes secret that you have\r\n  # created that contains your enterprise license. If you are not using an\r\n  # enterprise image or if you plan to introduce the license key via another\r\n  # route, then leave secretName blank (\"\") or set it to null.\r\n  # Requires Vault Enterprise 1.8 or later.\r\n  enterpriseLicense:\r\n    # The name of the Kubernetes secret that holds the enterprise license. The\r\n    # secret must be in the same namespace that Vault is installed into.\r\n    secretName: \"\"\r\n    # The key within the Kubernetes secret that holds the enterprise license.\r\n    secretKey: \"license\"\r\n\r\n  # Resource requests, limits, etc. for the server cluster placement. This\r\n  # should map directly to the value of the resources field for a PodSpec.\r\n  # By default no direct resource request is made.\r\n\r\n  image:\r\n    repository: \"hashicorp/vault\"\r\n    tag: \"1.18.1\"\r\n    # Overrides the default Image Pull Policy\r\n    pullPolicy: IfNotPresent\r\n\r\n  # Configure the Update Strategy Type for the StatefulSet\r\n  # See https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\r\n  updateStrategyType: \"OnDelete\"\r\n\r\n  # Configure the logging verbosity for the Vault server.\r\n  # Supported log levels include: trace, debug, info, warn, error\r\n  logLevel: \"\"\r\n\r\n  # Configure the logging format for the Vault server.\r\n  # Supported log formats include: standard, json\r\n  logFormat: \"\"\r\n\r\n  resources: {}\r\n  # resources:\r\n  #   requests:\r\n  #     memory: 256Mi\r\n  #     cpu: 250m\r\n  #   limits:\r\n  #     memory: 256Mi\r\n  #     cpu: 250m\r\n\r\n  # Ingress allows ingress services to be created to allow external access\r\n  # from Kubernetes to access Vault pods.\r\n  # If deployment is on OpenShift, the following block is ignored.\r\n  # In order to expose the service, use the route section below\r\n  ingress:\r\n    enabled: false\r\n    labels:\r\n      {}\r\n      # traffic: external\r\n    annotations:\r\n      {}\r\n      # |\r\n      # kubernetes.io/ingress.class: nginx\r\n      # kubernetes.io/tls-acme: \"true\"\r\n      #   or\r\n      # kubernetes.io/ingress.class: nginx\r\n      # kubernetes.io/tls-acme: \"true\"\r\n\r\n    # Optionally use ingressClassName instead of deprecated annotation.\r\n    # See: https://kubernetes.io/docs/concepts/services-networking/ingress/#deprecated-annotation\r\n    ingressClassName: \"\"\r\n\r\n    # As of Kubernetes 1.19, all Ingress Paths must have a pathType configured. The default value below should be sufficient in most cases.\r\n    # See: https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types for other possible values.\r\n    pathType: Prefix\r\n\r\n    # When HA mode is enabled and K8s service registration is being used,\r\n    # configure the ingress to point to the Vault active service.\r\n    activeService: true\r\n    hosts:\r\n      - host: chart-example.local\r\n        paths: []\r\n    ## Extra paths to prepend to the host configuration. This is useful when working with annotation based services.\r\n    extraPaths: []\r\n    # - path: /*\r\n    #   backend:\r\n    #     service:\r\n    #       name: ssl-redirect\r\n    #       port:\r\n    #         number: use-annotation\r\n    tls: []\r\n    #  - secretName: chart-example-tls\r\n    #    hosts:\r\n    #      - chart-example.local\r\n\r\n  # hostAliases is a list of aliases to be added to /etc/hosts. Specified as a YAML list.\r\n  hostAliases: []\r\n  # - ip: 127.0.0.1\r\n  #   hostnames:\r\n  #     - chart-example.local\r\n\r\n  # OpenShift only - create a route to expose the service\r\n  # By default the created route will be of type passthrough\r\n  route:\r\n    enabled: false\r\n\r\n    # When HA mode is enabled and K8s service registration is being used,\r\n    # configure the route to point to the Vault active service.\r\n    activeService: true\r\n\r\n    labels: {}\r\n    annotations: {}\r\n    host: chart-example.local\r\n    # tls will be passed directly to the route's TLS config, which\r\n    # can be used to configure other termination methods that terminate\r\n    # TLS at the router\r\n    tls:\r\n      termination: passthrough\r\n\r\n  # authDelegator enables a cluster role binding to be attached to the service\r\n  # account.  This cluster role binding can be used to setup Kubernetes auth\r\n  # method. See https://developer.hashicorp.com/vault/docs/auth/kubernetes\r\n  authDelegator:\r\n    enabled: true\r\n\r\n  # extraInitContainers is a list of init containers. Specified as a YAML list.\r\n  # This is useful if you need to run a script to provision TLS certificates or\r\n  # write out configuration files in a dynamic way.\r\n  extraInitContainers:\r\n    null\r\n    # # This example installs a plugin pulled from github into the /usr/local/libexec/vault/oauthapp folder,\r\n    # # which is defined in the volumes value.\r\n    # - name: oauthapp\r\n    #   image: \"alpine\"\r\n    #   command: [sh, -c]\r\n    #   args:\r\n    #     - cd /tmp \u0026\u0026\r\n    #       wget https://github.com/puppetlabs/vault-plugin-secrets-oauthapp/releases/download/v1.2.0/vault-plugin-secrets-oauthapp-v1.2.0-linux-amd64.tar.xz -O oauthapp.xz \u0026\u0026\r\n    #       tar -xf oauthapp.xz \u0026\u0026\r\n    #       mv vault-plugin-secrets-oauthapp-v1.2.0-linux-amd64 /usr/local/libexec/vault/oauthapp \u0026\u0026\r\n    #       chmod +x /usr/local/libexec/vault/oauthapp\r\n    #   volumeMounts:\r\n    #     - name: plugins\r\n    #       mountPath: /usr/local/libexec/vault\r\n\r\n  # extraContainers is a list of sidecar containers. Specified as a YAML list.\r\n  extraContainers: null\r\n\r\n  # shareProcessNamespace enables process namespace sharing between Vault and the extraContainers\r\n  # This is useful if Vault must be signaled, e.g. to send a SIGHUP for a log rotation\r\n  shareProcessNamespace: false\r\n\r\n  # extraArgs is a string containing additional Vault server arguments.\r\n  extraArgs: \"\"\r\n\r\n  # extraPorts is a list of extra ports. Specified as a YAML list.\r\n  # This is useful if you need to add additional ports to the statefulset in dynamic way.\r\n  extraPorts:\r\n    null\r\n    # - containerPort: 8300\r\n    #   name: http-monitoring\r\n\r\n  # Used to define custom readinessProbe settings\r\n  readinessProbe:\r\n    enabled: true\r\n    # If you need to use a http path instead of the default exec\r\n    # path: /v1/sys/health?standbyok=true\r\n\r\n    # Port number on which readinessProbe will be checked.\r\n    port: 8200\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 2\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 5\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 5\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 3\r\n  # Used to enable a livenessProbe for the pods\r\n  livenessProbe:\r\n    enabled: false\r\n    # Used to define a liveness exec command. If provided, exec is preferred to httpGet (path) as the livenessProbe handler.\r\n    execCommand: []\r\n    # - /bin/sh\r\n    # - -c\r\n    # - /vault/userconfig/mylivenessscript/run.sh\r\n    # Path for the livenessProbe to use httpGet as the livenessProbe handler\r\n    path: \"/v1/sys/health?standbyok=true\"\r\n    # Port number on which livenessProbe will be checked if httpGet is used as the livenessProbe handler\r\n    port: 8200\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 2\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 60\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 5\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 3\r\n\r\n  # Optional duration in seconds the pod needs to terminate gracefully.\r\n  # See: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/\r\n  terminationGracePeriodSeconds: 10\r\n\r\n  # Used to set the sleep time during the preStop step\r\n  preStopSleepSeconds: 5\r\n\r\n  # Used to define commands to run after the pod is ready.\r\n  # This can be used to automate processes such as initialization\r\n  # or boostrapping auth methods.\r\n  postStart: []\r\n  # - /bin/sh\r\n  # - -c\r\n  # - /vault/userconfig/myscript/run.sh\r\n\r\n  # extraEnvironmentVars is a list of extra environment variables to set with the stateful set. These could be\r\n  # used to include variables required for auto-unseal.\r\n  extraEnvironmentVars:\r\n    {}\r\n    # GOOGLE_REGION: global\r\n    # GOOGLE_PROJECT: myproject\r\n    # GOOGLE_APPLICATION_CREDENTIALS: /vault/userconfig/myproject/myproject-creds.json\r\n\r\n  # extraSecretEnvironmentVars is a list of extra environment variables to set with the stateful set.\r\n  # These variables take value from existing Secret objects.\r\n  extraSecretEnvironmentVars:\r\n    []\r\n    # - envName: AWS_SECRET_ACCESS_KEY\r\n    #   secretName: vault\r\n    #   secretKey: AWS_SECRET_ACCESS_KEY\r\n\r\n  # Deprecated: please use 'volumes' instead.\r\n  # extraVolumes is a list of extra volumes to mount. These will be exposed\r\n  # to Vault in the path `/vault/userconfig/\u003cname\u003e/`. The value below is\r\n  # an array of objects, examples are shown below.\r\n  extraVolumes:\r\n    []\r\n    # - type: secret (or \"configMap\")\r\n    #   name: my-secret\r\n    #   path: null # default is `/vault/userconfig`\r\n\r\n  # volumes is a list of volumes made available to all containers. These are rendered\r\n  # via toYaml rather than pre-processed like the extraVolumes value.\r\n  # The purpose is to make it easy to share volumes between containers.\r\n  volumes: null\r\n  #   - name: plugins\r\n  #     emptyDir: {}\r\n\r\n  # volumeMounts is a list of volumeMounts for the main server container. These are rendered\r\n  # via toYaml rather than pre-processed like the extraVolumes value.\r\n  # The purpose is to make it easy to share volumes between containers.\r\n  volumeMounts: null\r\n  #   - mountPath: /usr/local/libexec/vault\r\n  #     name: plugins\r\n  #     readOnly: true\r\n\r\n  # Affinity Settings\r\n  # Commenting out or setting as empty the affinity variable, will allow\r\n  # deployment to single node services such as Minikube\r\n  # This should be either a multi-line string or YAML matching the PodSpec's affinity field.\r\n  affinity: |\r\n    podAntiAffinity:\r\n      requiredDuringSchedulingIgnoredDuringExecution:\r\n        - labelSelector:\r\n            matchLabels:\r\n              app.kubernetes.io/name: {{ template \"vault.name\" . }}\r\n              app.kubernetes.io/instance: \"{{ .Release.Name }}\"\r\n              component: server\r\n          topologyKey: kubernetes.io/hostname\r\n\r\n  # Topology settings for server pods\r\n  # ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\r\n  # This should be either a multi-line string or YAML matching the topologySpreadConstraints array\r\n  # in a PodSpec.\r\n  topologySpreadConstraints: []\r\n\r\n  # Toleration Settings for server pods\r\n  # This should be either a multi-line string or YAML matching the Toleration array\r\n  # in a PodSpec.\r\n  tolerations: []\r\n\r\n  # nodeSelector labels for server pod assignment, formatted as a multi-line string or YAML map.\r\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\r\n  # Example:\r\n  # nodeSelector:\r\n  #   beta.kubernetes.io/arch: amd64\r\n  nodeSelector: {}\r\n\r\n  # Enables network policy for server pods\r\n  networkPolicy:\r\n    enabled: false\r\n    egress: []\r\n    # egress:\r\n    # - to:\r\n    #   - ipBlock:\r\n    #       cidr: 10.0.0.0/24\r\n    #   ports:\r\n    #   - protocol: TCP\r\n    #     port: 443\r\n    ingress:\r\n      - from:\r\n          - namespaceSelector: {}\r\n        ports:\r\n          - port: 8200\r\n            protocol: TCP\r\n          - port: 8201\r\n            protocol: TCP\r\n\r\n  # Priority class for server pods\r\n  priorityClassName: \"\"\r\n\r\n  # Extra labels to attach to the server pods\r\n  # This should be a YAML map of the labels to apply to the server pods\r\n  extraLabels: {}\r\n\r\n  # Extra annotations to attach to the server pods\r\n  # This can either be YAML or a YAML-formatted multi-line templated string map\r\n  # of the annotations to apply to the server pods\r\n  annotations: {}\r\n\r\n  # Add an annotation to the server configmap and the statefulset pods,\r\n  # vaultproject.io/config-checksum, that is a hash of the Vault configuration.\r\n  # This can be used together with an OnDelete deployment strategy to help\r\n  # identify which pods still need to be deleted during a deployment to pick up\r\n  # any configuration changes.\r\n  includeConfigAnnotation: false\r\n\r\n  # Enables a headless service to be used by the Vault Statefulset\r\n  service:\r\n    enabled: true\r\n    # Enable or disable the vault-active service, which selects Vault pods that\r\n    # have labeled themselves as the cluster leader with `vault-active: \"true\"`.\r\n    active:\r\n      enabled: true\r\n      # Extra annotations for the service definition. This can either be YAML or a\r\n      # YAML-formatted multi-line templated string map of the annotations to apply\r\n      # to the active service.\r\n      annotations: {}\r\n    # Enable or disable the vault-standby service, which selects Vault pods that\r\n    # have labeled themselves as a cluster follower with `vault-active: \"false\"`.\r\n    standby:\r\n      enabled: true\r\n      # Extra annotations for the service definition. This can either be YAML or a\r\n      # YAML-formatted multi-line templated string map of the annotations to apply\r\n      # to the standby service.\r\n      annotations: {}\r\n    # If enabled, the service selectors will include `app.kubernetes.io/instance: {{ .Release.Name }}`\r\n    # When disabled, services may select Vault pods not deployed from the chart.\r\n    # Does not affect the headless vault-internal service with `ClusterIP: None`\r\n    instanceSelector:\r\n      enabled: true\r\n    # clusterIP controls whether a Cluster IP address is attached to the\r\n    # Vault service within Kubernetes.  By default, the Vault service will\r\n    # be given a Cluster IP address, set to None to disable.  When disabled\r\n    # Kubernetes will create a \"headless\" service.  Headless services can be\r\n    # used to communicate with pods directly through DNS instead of a round-robin\r\n    # load balancer.\r\n    # clusterIP: None\r\n\r\n    # Configures the service type for the main Vault service.  Can be ClusterIP\r\n    # or NodePort.\r\n    #type: ClusterIP\r\n\r\n    # The IP family and IP families options are to set the behaviour in a dual-stack environment.\r\n    # Omitting these values will let the service fall back to whatever the CNI dictates the defaults\r\n    # should be.\r\n    # These are only supported for kubernetes versions \u003e=1.23.0\r\n    #\r\n    # Configures the service's supported IP family policy, can be either:\r\n    #     SingleStack: Single-stack service. The control plane allocates a cluster IP for the Service, using the first configured service cluster IP range.\r\n    #     PreferDualStack: Allocates IPv4 and IPv6 cluster IPs for the Service.\r\n    #     RequireDualStack: Allocates Service .spec.ClusterIPs from both IPv4 and IPv6 address ranges.\r\n    ipFamilyPolicy: \"\"\r\n\r\n    # Sets the families that should be supported and the order in which they should be applied to ClusterIP as well.\r\n    # Can be IPv4 and/or IPv6.\r\n    ipFamilies: []\r\n\r\n    # Do not wait for pods to be ready before including them in the services'\r\n    # targets. Does not apply to the headless service, which is used for\r\n    # cluster-internal communication.\r\n    publishNotReadyAddresses: true\r\n\r\n    # The externalTrafficPolicy can be set to either Cluster or Local\r\n    # and is only valid for LoadBalancer and NodePort service types.\r\n    # The default value is Cluster.\r\n    # ref: https://kubernetes.io/docs/concepts/services-networking/service/#external-traffic-policy\r\n    externalTrafficPolicy: Cluster\r\n\r\n    # If type is set to \"NodePort\", a specific nodePort value can be configured,\r\n    # will be random if left blank.\r\n    #nodePort: 30000\r\n\r\n    # When HA mode is enabled\r\n    # If type is set to \"NodePort\", a specific nodePort value can be configured,\r\n    # will be random if left blank.\r\n    #activeNodePort: 30001\r\n\r\n    # When HA mode is enabled\r\n    # If type is set to \"NodePort\", a specific nodePort value can be configured,\r\n    # will be random if left blank.\r\n    #standbyNodePort: 30002\r\n\r\n    # Port on which Vault server is listening\r\n    port: 8200\r\n    # Target port to which the service should be mapped to\r\n    targetPort: 8200\r\n    # Extra annotations for the service definition. This can either be YAML or a\r\n    # YAML-formatted multi-line templated string map of the annotations to apply\r\n    # to the service.\r\n    annotations: {}\r\n\r\n  # This configures the Vault Statefulset to create a PVC for data\r\n  # storage when using the file or raft backend storage engines.\r\n  # See https://developer.hashicorp.com/vault/docs/configuration/storage to know more\r\n  dataStorage:\r\n    enabled: true\r\n    # Size of the PVC created\r\n    size: 10Gi\r\n    # Location where the PVC will be mounted.\r\n    mountPath: \"/vault/data\"\r\n    # Name of the storage class to use.  If null it will use the\r\n    # configured default Storage Class.\r\n    storageClass: null\r\n    # Access Mode of the storage device being used for the PVC\r\n    accessMode: ReadWriteOnce\r\n    # Annotations to apply to the PVC\r\n    annotations: {}\r\n    # Labels to apply to the PVC\r\n    labels: {}\r\n\r\n  # Persistent Volume Claim (PVC) retention policy\r\n  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention\r\n  # Example:\r\n  # persistentVolumeClaimRetentionPolicy:\r\n  #   whenDeleted: Retain\r\n  #   whenScaled: Retain\r\n  persistentVolumeClaimRetentionPolicy: {}\r\n\r\n  # This configures the Vault Statefulset to create a PVC for audit\r\n  # logs.  Once Vault is deployed, initialized, and unsealed, Vault must\r\n  # be configured to use this for audit logs.  This will be mounted to\r\n  # /vault/audit\r\n  # See https://developer.hashicorp.com/vault/docs/audit to know more\r\n  auditStorage:\r\n    enabled: false\r\n    # Size of the PVC created\r\n    size: 10Gi\r\n    # Location where the PVC will be mounted.\r\n    mountPath: \"/vault/audit\"\r\n    # Name of the storage class to use.  If null it will use the\r\n    # configured default Storage Class.\r\n    storageClass: null\r\n    # Access Mode of the storage device being used for the PVC\r\n    accessMode: ReadWriteOnce\r\n    # Annotations to apply to the PVC\r\n    annotations: {}\r\n    # Labels to apply to the PVC\r\n    labels: {}\r\n\r\n  # Run Vault in \"dev\" mode. This requires no further setup, no state management,\r\n  # and no initialization. This is useful for experimenting with Vault without\r\n  # needing to unseal, store keys, et. al. All data is lost on restart - do not\r\n  # use dev mode for anything other than experimenting.\r\n  # See https://developer.hashicorp.com/vault/docs/concepts/dev-server to know more\r\n  dev:\r\n    enabled: false\r\n\r\n    # Set VAULT_DEV_ROOT_TOKEN_ID value\r\n    devRootToken: \"root\"\r\n\r\n  # Run Vault in \"standalone\" mode. This is the default mode that will deploy if\r\n  # no arguments are given to helm. This requires a PVC for data storage to use\r\n  # the \"file\" backend.  This mode is not highly available and should not be scaled\r\n  # past a single replica.\r\n  standalone:\r\n    enabled: \"-\"\r\n\r\n    # config is a raw string of default configuration when using a Stateful\r\n    # deployment. Default is to use a PersistentVolumeClaim mounted at /vault/data\r\n    # and store data there. This is only used when using a Replica count of 1, and\r\n    # using a stateful set. Supported formats are HCL and JSON.\r\n\r\n    # Note: Configuration files are stored in ConfigMaps so sensitive data\r\n    # such as passwords should be either mounted through extraSecretEnvironmentVars\r\n    # or through a Kube secret. For more information see:\r\n    # https://developer.hashicorp.com/vault/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations\r\n    config: |-\r\n      ui = true\r\n\r\n      listener \"tcp\" {\r\n        tls_disable = 1\r\n        address = \"[::]:8200\"\r\n        cluster_address = \"[::]:8201\"\r\n        # Enable unauthenticated metrics access (necessary for Prometheus Operator)\r\n        #telemetry {\r\n        #  unauthenticated_metrics_access = \"true\"\r\n        #}\r\n      }\r\n      storage \"file\" {\r\n        path = \"/vault/data\"\r\n      }\r\n\r\n      # Example configuration for using auto-unseal, using Google Cloud KMS. The\r\n      # GKMS keys must already exist, and the cluster must have a service account\r\n      # that is authorized to access GCP KMS.\r\n      #seal \"gcpckms\" {\r\n      #   project     = \"vault-helm-dev\"\r\n      #   region      = \"global\"\r\n      #   key_ring    = \"vault-helm-unseal-kr\"\r\n      #   crypto_key  = \"vault-helm-unseal-key\"\r\n      #}\r\n\r\n      # Example configuration for enabling Prometheus metrics in your config.\r\n      #telemetry {\r\n      #  prometheus_retention_time = \"30s\"\r\n      #  disable_hostname = true\r\n      #}\r\n\r\n  # Run Vault in \"HA\" mode. There are no storage requirements unless the audit log\r\n  # persistence is required.  In HA mode Vault will configure itself to use Consul\r\n  # for its storage backend.  The default configuration provided will work the Consul\r\n  # Helm project by default.  It is possible to manually configure Vault to use a\r\n  # different HA backend.\r\n  ha:\r\n    enabled: false\r\n    replicas: 3\r\n\r\n    # Set the api_addr configuration for Vault HA\r\n    # See https://developer.hashicorp.com/vault/docs/configuration#api_addr\r\n    # If set to null, this will be set to the Pod IP Address\r\n    apiAddr: null\r\n\r\n    # Set the cluster_addr configuration for Vault HA\r\n    # See https://developer.hashicorp.com/vault/docs/configuration#cluster_addr\r\n    # If set to null, this will be set to https://$(HOSTNAME).{{ template \"vault.fullname\" . }}-internal:8201\r\n    clusterAddr: null\r\n\r\n    # Enables Vault's integrated Raft storage.  Unlike the typical HA modes where\r\n    # Vault's persistence is external (such as Consul), enabling Raft mode will create\r\n    # persistent volumes for Vault to store data according to the configuration under server.dataStorage.\r\n    # The Vault cluster will coordinate leader elections and failovers internally.\r\n    raft:\r\n      # Enables Raft integrated storage\r\n      enabled: false\r\n      # Set the Node Raft ID to the name of the pod\r\n      setNodeId: false\r\n\r\n      # Note: Configuration files are stored in ConfigMaps so sensitive data\r\n      # such as passwords should be either mounted through extraSecretEnvironmentVars\r\n      # or through a Kube secret.  For more information see:\r\n      # https://developer.hashicorp.com/vault/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations\r\n      # Supported formats are HCL and JSON.\r\n      config: |\r\n        ui = true\r\n\r\n        listener \"tcp\" {\r\n          tls_disable = 1\r\n          address = \"[::]:8200\"\r\n          cluster_address = \"[::]:8201\"\r\n          # Enable unauthenticated metrics access (necessary for Prometheus Operator)\r\n          #telemetry {\r\n          #  unauthenticated_metrics_access = \"true\"\r\n          #}\r\n        }\r\n\r\n        storage \"raft\" {\r\n          path = \"/vault/data\"\r\n        }\r\n\r\n        service_registration \"kubernetes\" {}\r\n\r\n    # config is a raw string of default configuration when using a Stateful\r\n    # deployment. Default is to use a Consul for its HA storage backend.\r\n    # Supported formats are HCL and JSON.\r\n\r\n    # Note: Configuration files are stored in ConfigMaps so sensitive data\r\n    # such as passwords should be either mounted through extraSecretEnvironmentVars\r\n    # or through a Kube secret. For more information see:\r\n    # https://developer.hashicorp.com/vault/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations\r\n    config: |\r\n      ui = true\r\n\r\n      listener \"tcp\" {\r\n        tls_disable = 1\r\n        address = \"[::]:8200\"\r\n        cluster_address = \"[::]:8201\"\r\n      }\r\n      storage \"consul\" {\r\n        path = \"vault\"\r\n        address = \"HOST_IP:8500\"\r\n      }\r\n\r\n      service_registration \"kubernetes\" {}\r\n\r\n      # Example configuration for using auto-unseal, using Google Cloud KMS. The\r\n      # GKMS keys must already exist, and the cluster must have a service account\r\n      # that is authorized to access GCP KMS.\r\n      #seal \"gcpckms\" {\r\n      #   project     = \"vault-helm-dev-246514\"\r\n      #   region      = \"global\"\r\n      #   key_ring    = \"vault-helm-unseal-kr\"\r\n      #   crypto_key  = \"vault-helm-unseal-key\"\r\n      #}\r\n\r\n      # Example configuration for enabling Prometheus metrics.\r\n      # If you are using Prometheus Operator you can enable a ServiceMonitor resource below.\r\n      # You may wish to enable unauthenticated metrics in the listener block above.\r\n      #telemetry {\r\n      #  prometheus_retention_time = \"30s\"\r\n      #  disable_hostname = true\r\n      #}\r\n\r\n    # A disruption budget limits the number of pods of a replicated application\r\n    # that are down simultaneously from voluntary disruptions\r\n    disruptionBudget:\r\n      enabled: true\r\n\r\n      # maxUnavailable will default to (n/2)-1 where n is the number of\r\n      # replicas. If you'd like a custom value, you can specify an override here.\r\n      maxUnavailable: null\r\n\r\n  # Definition of the serviceAccount used to run Vault.\r\n  # These options are also used when using an external Vault server to validate\r\n  # Kubernetes tokens.\r\n  serviceAccount:\r\n    # Specifies whether a service account should be created\r\n    create: true\r\n    # The name of the service account to use.\r\n    # If not set and create is true, a name is generated using the fullname template\r\n    name: \"vault-sa\"\r\n    # Create a Secret API object to store a non-expiring token for the service account.\r\n    # Prior to v1.24.0, Kubernetes used to generate this secret for each service account by default.\r\n    # Kubernetes now recommends using short-lived tokens from the TokenRequest API or projected volumes instead if possible.\r\n    # For more details, see https://kubernetes.io/docs/concepts/configuration/secret/#service-account-token-secrets\r\n    # serviceAccount.create must be equal to 'true' in order to use this feature.\r\n    createSecret: true\r\n    # Extra annotations for the serviceAccount definition. This can either be\r\n    # YAML or a YAML-formatted multi-line templated string map of the\r\n    # annotations to apply to the serviceAccount.\r\n    annotations: {}\r\n    # Extra labels to attach to the serviceAccount\r\n    # This should be a YAML map of the labels to apply to the serviceAccount\r\n    extraLabels: {}\r\n    # Enable or disable a service account role binding with the permissions required for\r\n    # Vault's Kubernetes service_registration config option.\r\n    # See https://developer.hashicorp.com/vault/docs/configuration/service-registration/kubernetes\r\n    serviceDiscovery:\r\n      enabled: true\r\n\r\n  # Settings for the statefulSet used to run Vault.\r\n  statefulSet:\r\n    # Extra annotations for the statefulSet. This can either be YAML or a\r\n    # YAML-formatted multi-line templated string map of the annotations to apply\r\n    # to the statefulSet.\r\n    annotations: {}\r\n\r\n    # Set the pod and container security contexts.\r\n    # If not set, these will default to, and for *not* OpenShift:\r\n    # pod:\r\n    #   runAsNonRoot: true\r\n    #   runAsGroup: {{ .Values.server.gid | default 1000 }}\r\n    #   runAsUser: {{ .Values.server.uid | default 100 }}\r\n    #   fsGroup: {{ .Values.server.gid | default 1000 }}\r\n    # container:\r\n    #   allowPrivilegeEscalation: false\r\n    #\r\n    # If not set, these will default to, and for OpenShift:\r\n    # pod: {}\r\n    # container: {}\r\n    securityContext:\r\n      pod: {}\r\n      container: {}\r\n\r\n  # Should the server pods run on the host network\r\n  hostNetwork: false\r\n\r\n# Vault UI\r\nui:\r\n  # True if you want to create a Service entry for the Vault UI.\r\n  #\r\n  # serviceType can be used to control the type of service created. For\r\n  # example, setting this to \"LoadBalancer\" will create an external load\r\n  # balancer (for supported K8S installations) to access the UI.\r\n  enabled: false\r\n  publishNotReadyAddresses: true\r\n  # The service should only contain selectors for active Vault pod\r\n  activeVaultPodOnly: false\r\n  serviceType: \"ClusterIP\"\r\n  serviceNodePort: null\r\n  externalPort: 8200\r\n  targetPort: 8200\r\n\r\n  # The IP family and IP families options are to set the behaviour in a dual-stack environment.\r\n  # Omitting these values will let the service fall back to whatever the CNI dictates the defaults\r\n  # should be.\r\n  # These are only supported for kubernetes versions \u003e=1.23.0\r\n  #\r\n  # Configures the service's supported IP family, can be either:\r\n  #     SingleStack: Single-stack service. The control plane allocates a cluster IP for the Service, using the first configured service cluster IP range.\r\n  #     PreferDualStack: Allocates IPv4 and IPv6 cluster IPs for the Service.\r\n  #     RequireDualStack: Allocates Service .spec.ClusterIPs from both IPv4 and IPv6 address ranges.\r\n  serviceIPFamilyPolicy: \"\"\r\n\r\n  # Sets the families that should be supported and the order in which they should be applied to ClusterIP as well\r\n  # Can be IPv4 and/or IPv6.\r\n  serviceIPFamilies: []\r\n\r\n  # The externalTrafficPolicy can be set to either Cluster or Local\r\n  # and is only valid for LoadBalancer and NodePort service types.\r\n  # The default value is Cluster.\r\n  # ref: https://kubernetes.io/docs/concepts/services-networking/service/#external-traffic-policy\r\n  externalTrafficPolicy: Cluster\r\n\r\n  #loadBalancerSourceRanges:\r\n  #   - 10.0.0.0/16\r\n  #   - 1.78.23.3/32\r\n\r\n  # loadBalancerIP:\r\n\r\n  # Extra annotations to attach to the ui service\r\n  # This can either be YAML or a YAML-formatted multi-line templated string map\r\n  # of the annotations to apply to the ui service\r\n  annotations: {}\r\n\r\n# secrets-store-csi-driver-provider-vault\r\ncsi:\r\n  # True if you want to install a secrets-store-csi-driver-provider-vault daemonset.\r\n  #\r\n  # Requires installing the secrets-store-csi-driver separately, see:\r\n  # https://github.com/kubernetes-sigs/secrets-store-csi-driver#install-the-secrets-store-csi-driver\r\n  #\r\n  # With the driver and provider installed, you can mount Vault secrets into volumes\r\n  # similar to the Vault Agent injector, and you can also sync those secrets into\r\n  # Kubernetes secrets.\r\n  enabled: false\r\n\r\n  image:\r\n    repository: \"hashicorp/vault-csi-provider\"\r\n    tag: \"1.5.0\"\r\n    pullPolicy: IfNotPresent\r\n\r\n  # volumes is a list of volumes made available to all containers. These are rendered\r\n  # via toYaml rather than pre-processed like the extraVolumes value.\r\n  # The purpose is to make it easy to share volumes between containers.\r\n  volumes: null\r\n  # - name: tls\r\n  #   secret:\r\n  #     secretName: vault-tls\r\n\r\n  # volumeMounts is a list of volumeMounts for the main server container. These are rendered\r\n  # via toYaml rather than pre-processed like the extraVolumes value.\r\n  # The purpose is to make it easy to share volumes between containers.\r\n  volumeMounts: null\r\n  # - name: tls\r\n  #   mountPath: \"/vault/tls\"\r\n  #   readOnly: true\r\n\r\n  resources: {}\r\n  # resources:\r\n  #   requests:\r\n  #     cpu: 50m\r\n  #     memory: 128Mi\r\n  #   limits:\r\n  #     cpu: 50m\r\n  #     memory: 128Mi\r\n\r\n  # Override the default secret name for the CSI Provider's HMAC key used for\r\n  # generating secret versions.\r\n  hmacSecretName: \"\"\r\n\r\n  # Allow modification of the hostNetwork parameter to avoid the need of a\r\n  # dedicated pod ip\r\n  hostNetwork: false\r\n\r\n  # Settings for the daemonSet used to run the provider.\r\n  daemonSet:\r\n    updateStrategy:\r\n      type: RollingUpdate\r\n      maxUnavailable: \"\"\r\n    # Extra annotations for the daemonSet. This can either be YAML or a\r\n    # YAML-formatted multi-line templated string map of the annotations to apply\r\n    # to the daemonSet.\r\n    annotations: {}\r\n    # Provider host path (must match the CSI provider's path)\r\n    providersDir: \"/etc/kubernetes/secrets-store-csi-providers\"\r\n    # Kubelet host path\r\n    kubeletRootDir: \"/var/lib/kubelet\"\r\n    # Extra labels to attach to the vault-csi-provider daemonSet\r\n    # This should be a YAML map of the labels to apply to the csi provider daemonSet\r\n    extraLabels: {}\r\n    # security context for the pod template and container in the csi provider daemonSet\r\n    securityContext:\r\n      pod: {}\r\n      container: {}\r\n\r\n  pod:\r\n    # Extra annotations for the provider pods. This can either be YAML or a\r\n    # YAML-formatted multi-line templated string map of the annotations to apply\r\n    # to the pod.\r\n    annotations: {}\r\n\r\n    # Toleration Settings for provider pods\r\n    # This should be either a multi-line string or YAML matching the Toleration array\r\n    # in a PodSpec.\r\n    tolerations: []\r\n\r\n    # nodeSelector labels for csi pod assignment, formatted as a multi-line string or YAML map.\r\n    # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\r\n    # Example:\r\n    # nodeSelector:\r\n    #   beta.kubernetes.io/arch: amd64\r\n    nodeSelector: {}\r\n\r\n    # Affinity Settings\r\n    # This should be either a multi-line string or YAML matching the PodSpec's affinity field.\r\n    affinity: {}\r\n\r\n    # Extra labels to attach to the vault-csi-provider pod\r\n    # This should be a YAML map of the labels to apply to the csi provider pod\r\n    extraLabels: {}\r\n\r\n  agent:\r\n    enabled: true\r\n    extraArgs: []\r\n\r\n    image:\r\n      repository: \"hashicorp/vault\"\r\n      tag: \"1.18.1\"\r\n      pullPolicy: IfNotPresent\r\n\r\n    logFormat: standard\r\n    logLevel: info\r\n\r\n    resources: {}\r\n    # resources:\r\n    #   requests:\r\n    #     memory: 256Mi\r\n    #     cpu: 250m\r\n    #   limits:\r\n    #     memory: 256Mi\r\n    #     cpu: 250m\r\n\r\n  # Priority class for csi pods\r\n  priorityClassName: \"\"\r\n\r\n  serviceAccount:\r\n    # Extra annotations for the serviceAccount definition. This can either be\r\n    # YAML or a YAML-formatted multi-line templated string map of the\r\n    # annotations to apply to the serviceAccount.\r\n    annotations: {}\r\n\r\n    # Extra labels to attach to the vault-csi-provider serviceAccount\r\n    # This should be a YAML map of the labels to apply to the csi provider serviceAccount\r\n    extraLabels: {}\r\n\r\n  # Used to configure readinessProbe for the pods.\r\n  readinessProbe:\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 2\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 5\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 5\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 3\r\n  # Used to configure livenessProbe for the pods.\r\n  livenessProbe:\r\n    # When a probe fails, Kubernetes will try failureThreshold times before giving up\r\n    failureThreshold: 2\r\n    # Number of seconds after the container has started before probe initiates\r\n    initialDelaySeconds: 5\r\n    # How often (in seconds) to perform the probe\r\n    periodSeconds: 5\r\n    # Minimum consecutive successes for the probe to be considered successful after having failed\r\n    successThreshold: 1\r\n    # Number of seconds after which the probe times out.\r\n    timeoutSeconds: 3\r\n\r\n  # Configures the log level for the Vault CSI provider.\r\n  # Supported log levels include: trace, debug, info, warn, error, and off\r\n  logLevel: \"info\"\r\n\r\n  # Deprecated, set logLevel to debug instead.\r\n  # If set to true, the logLevel will be set to debug.\r\n  debug: false\r\n\r\n  # Pass arbitrary additional arguments to vault-csi-provider.\r\n  # See https://developer.hashicorp.com/vault/docs/platform/k8s/csi/configurations#command-line-arguments\r\n  # for the available command line flags.\r\n  extraArgs: []\r\n\r\n# Vault is able to collect and publish various runtime metrics.\r\n# Enabling this feature requires setting adding `telemetry{}` stanza to\r\n# the Vault configuration. There are a few examples included in the `config` sections above.\r\n#\r\n# For more information see:\r\n# https://developer.hashicorp.com/vault/docs/configuration/telemetry\r\n# https://developer.hashicorp.com/vault/docs/internals/telemetry\r\nserverTelemetry:\r\n  # Enable support for the Prometheus Operator. If authorization is not set for authenticating\r\n  # to Vault's metrics endpoint, the following Vault server `telemetry{}` config must be included\r\n  # in the `listener \"tcp\"{}` stanza\r\n  #  telemetry {\r\n  #    unauthenticated_metrics_access = \"true\"\r\n  #  }\r\n  #\r\n  # See the `standalone.config` for a more complete example of this.\r\n  #\r\n  # In addition, a top level `telemetry{}` stanza must also be included in the Vault configuration:\r\n  #\r\n  # example:\r\n  #  telemetry {\r\n  #    prometheus_retention_time = \"30s\"\r\n  #    disable_hostname = true\r\n  #  }\r\n  #\r\n  # Configuration for monitoring the Vault server.\r\n  serviceMonitor:\r\n    # The Prometheus operator *must* be installed before enabling this feature,\r\n    # if not the chart will fail to install due to missing CustomResourceDefinitions\r\n    # provided by the operator.\r\n    #\r\n    # Instructions on how to install the Helm chart can be found here:\r\n    #  https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack\r\n    # More information can be found here:\r\n    #  https://github.com/prometheus-operator/prometheus-operator\r\n    #  https://github.com/prometheus-operator/kube-prometheus\r\n\r\n    # Enable deployment of the Vault Server ServiceMonitor CustomResource.\r\n    enabled: false\r\n\r\n    # Selector labels to add to the ServiceMonitor.\r\n    # When empty, defaults to:\r\n    #  release: prometheus\r\n    selectors: {}\r\n\r\n    # Interval at which Prometheus scrapes metrics\r\n    interval: 30s\r\n\r\n    # Timeout for Prometheus scrapes\r\n    scrapeTimeout: 10s\r\n\r\n    # tlsConfig used for scraping the Vault metrics API.\r\n    # See API reference: https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.TLSConfig\r\n    # example:\r\n    # tlsConfig:\r\n    #   ca:\r\n    #     secret:\r\n    #       name: vault-metrics-client\r\n    #       key: ca.crt\r\n    tlsConfig: {}\r\n\r\n    # authorization used for scraping the Vault metrics API.\r\n    # See API reference: https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.SafeAuthorization\r\n    # example:\r\n    # authorization:\r\n    #   credentials:\r\n    #     name: vault-metrics-client\r\n    #     key: token\r\n    authorization: {}\r\n\r\n  prometheusRules:\r\n    # The Prometheus operator *must* be installed before enabling this feature,\r\n    # if not the chart will fail to install due to missing CustomResourceDefinitions\r\n    # provided by the operator.\r\n\r\n    # Deploy the PrometheusRule custom resource for AlertManager based alerts.\r\n    # Requires that AlertManager is properly deployed.\r\n    enabled: false\r\n\r\n    # Selector labels to add to the PrometheusRules.\r\n    # When empty, defaults to:\r\n    #  release: prometheus\r\n    selectors: {}\r\n\r\n    # Some example rules.\r\n    rules: []\r\n    #  - alert: vault-HighResponseTime\r\n    #    annotations:\r\n    #      message: The response time of Vault is over 500ms on average over the last 5 minutes.\r\n    #    expr: vault_core_handle_request{quantile=\"0.5\", namespace=\"mynamespace\"} \u003e 500\r\n    #    for: 5m\r\n    #    labels:\r\n    #      severity: warning\r\n    #  - alert: vault-HighResponseTime\r\n    #    annotations:\r\n    #      message: The response time of Vault is over 1s on average over the last 5 minutes.\r\n    #    expr: vault_core_handle_request{quantile=\"0.5\", namespace=\"mynamespace\"} \u003e 1000\r\n    #    for: 5m\r\n    #    labels:\r\n    #      severity: critical\r\n"
            ],
            "verify": false,
            "version": "0.29.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "repository_password"
              }
            ]
          ],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "vault_auth_backend",
      "name": "kubernetes",
      "provider": "provider[\"registry.terraform.io/hashicorp/vault\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "accessor": "auth_kubernetes_d0422634",
            "description": "",
            "disable_remount": false,
            "id": "kubernetes",
            "identity_token_key": null,
            "local": false,
            "namespace": null,
            "path": "kubernetes",
            "tune": [],
            "type": "kubernetes"
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "vault_kubernetes_auth_backend_config",
      "name": "kubernetes_config",
      "provider": "provider[\"registry.terraform.io/hashicorp/vault\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "backend": "kubernetes",
            "disable_iss_validation": false,
            "disable_local_ca_jwt": false,
            "id": "auth/kubernetes/config",
            "issuer": "",
            "kubernetes_ca_cert": "-----BEGIN CERTIFICATE-----\nMIIDBTCCAe2gAwIBAgIIVAeZdzNGgIwwDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yNDEyMTcwOTM1NTJaFw0zNDEyMTUwOTQwNTJaMBUx\nEzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQCY7ZAAxWvoghR0Wv8oW7LcTN1zLd++b+kWFmBAigxMA1MJTaauC1vBMAS1\nEgHaHoxgRh4fBev7Y8B8qp+H2U2YXXRfcIcjp/3UXtuMot6P3lRjLytSuwiu/HzF\nojeueg+oL4lRfUIt1RvzlDEnljO9EqhCsWyBQ/S6BdscqTFXr6dR6oywwu0eIPKX\n/cc3LnCj5JHacbpRBpdCUzt01WZXPu75Dl3HAjRiW/h+Yvr6Ref/I79ACS3Zg0MH\nWoroEI7RoCMMNF0oUYG2OESG+LvxCfGKl4RTZ882/DgiqAAWsVwY13tO1RJZs4HJ\nSDS7S33g4qVoXslPK4Ax4WcqgKGLAgMBAAGjWTBXMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQewLCCAkI3J2aP0B5ugslSWleHMjAV\nBgNVHREEDjAMggprdWJlcm5ldGVzMA0GCSqGSIb3DQEBCwUAA4IBAQBcau9sXYBS\nzE9XGncPACW2VR39kbMdv3GSneOzcWgP212FIkRAX+E/HA4FCjhPCm5KwdNW8MaC\nhiTdIEtzrUBdudc4IKAF8Y/vPRjOhcdvzqL5SF6Pz9kZUPkgIk4rPKm3VANsBpE7\nKnG+TwkoI3UiOF8kUj6SHIH+5+Ejx38KuS8UhMHF7zF76mtE9ieBCxMCYF90VVqa\niGVimu4gequUe+q0u/Fbo2K9AKPMiGQCdjXpMdjmM0+odvALUsby4khYS+q5FNwu\n3J3/WQoeHaDpC9fSk2kW6A3i6xzJYJ7FC9ExZpcRXUKcSgssKotK7aOmAZ6CYvWX\ncQVBgq2U3QDN\n-----END CERTIFICATE-----\n",
            "kubernetes_host": "https://48F1125BCC8DD3418816A72EE059E51F.gr7.us-east-1.eks.amazonaws.com",
            "namespace": null,
            "pem_keys": null,
            "token_reviewer_jwt": "eyJhbGciOiJSUzI1NiIsImtpZCI6InlYb1QxbmhZS2pnYTdOR3dxenBKMU8wRWJlMmhvRUVmYXpWZWxQbEJnbVEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJ2YXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ2YXVsdC1zYS10b2tlbiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJ2YXVsdC1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBmNjllYzgzLTljODYtNDRhYy1iYzBkLWNiNDhiN2FmNTEyMiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDp2YXVsdDp2YXVsdC1zYSJ9.ebaAYjDMz7lWq_LI1B6yzx8hA-1ac8gRDkSwfmKjschfiQsW72fyDD6wBVPDSWJrHx0H85ethOTZwVfj86Rwh2rPy5ZlCMtw-ezGwuHW5KJ9Tu7TE3lU9ZESsWWhVko-jDPMNHMBuaUxe3jfOL9TsrlY_PBES_lXuF0Ds_WeAW_MK3Md0Lw3MWTBWIPY1i7e97C3nC_7cxHfItJlyuNcLIAXDpIjb3eaAJAJig5PURJwP7d5w-J6JtpaG8SFbnACzsz-VSeZ5Hxn2IfdacHIPExIVST_RQTVA3o3KYOPORJmR7XeLgD9uhQGZABabTSi2acAzV-IEIRcloy3RltHFA",
            "use_annotations_as_alias_metadata": false
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "kubernetes_ca_cert"
              }
            ],
            [
              {
                "type": "get_attr",
                "value": "token_reviewer_jwt"
              }
            ]
          ],
          "private": "bnVsbA==",
          "dependencies": [
            "data.aws_eks_cluster.cluster",
            "data.aws_eks_cluster_auth.cluster",
            "data.kubernetes_secret.sa_token",
            "vault_auth_backend.kubernetes"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "vault_kubernetes_auth_backend_role",
      "name": "vault_role",
      "provider": "provider[\"registry.terraform.io/hashicorp/vault\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "alias_name_source": "serviceaccount_uid",
            "audience": null,
            "backend": "kubernetes",
            "bound_service_account_names": [
              "vault-sa"
            ],
            "bound_service_account_namespaces": [
              "vault"
            ],
            "id": "auth/kubernetes/role/vault-role",
            "namespace": null,
            "role_name": "vault-role",
            "token_bound_cidrs": null,
            "token_explicit_max_ttl": 0,
            "token_max_ttl": 3600,
            "token_no_default_policy": false,
            "token_num_uses": 0,
            "token_period": 0,
            "token_policies": [
              "default",
              "mysecret"
            ],
            "token_ttl": 0,
            "token_type": "default"
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "vault_auth_backend.kubernetes"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "vault_policy",
      "name": "mysecret",
      "provider": "provider[\"registry.terraform.io/hashicorp/vault\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "mysecret",
            "name": "mysecret",
            "namespace": null,
            "policy": "path \"kv-v2/data/fakeapp/mysecret\" {\r\n  capabilities = [\"read\"]\r\n}\r\n"
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    }
  ],
  "check_results": null
}
